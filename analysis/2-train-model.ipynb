{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a967e3f-8015-4de0-ae1d-b331fcfcdd5a",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "\n",
    "Now we get into the nuts and bolts of training the model. First and foremost lets load the data from the prior step. Next we divide into train and test where the first 40k images will be used for training and the remainder for testing. We also import `utils` which contains some functions used during the model training process. In particular:\n",
    "\n",
    "- `scale_images()`: Is a tool for standardizing (or inverting) images to have mean: 0 and sd: 1\n",
    "- `add_noise()`: Adds random noise to the images but clips to be within tolerance for pixel ranges\n",
    "- `get_batch()`: Is a dataloader which grabs a batch of images (default 1000 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d390c62-f1a8-4a16-836f-912b8fc9366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load modeling utilities\n",
    "sys.path.append('../src/')\n",
    "import utils\n",
    "\n",
    "# Load images\n",
    "images = torch.load('../data/images.pt')\n",
    "\n",
    "# Divide into train and test\n",
    "train = images[0:40000]\n",
    "test = images[40000:50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a880172-5af9-45b9-b085-3afee9664f89",
   "metadata": {},
   "source": [
    "Now we define our neural network architecture using `nn.Module` from `torch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d73b9cef-0a59-4282-a689-cc10542dbd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 1, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deb7825b-a2b7-4a87-85bc-031f1a05a892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1, 64, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, targets = utils.get_batch(train)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    # Zero the gradients at the beginning of each epoch\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass: compute the output\n",
    "    outputs = model(input_images)\n",
    "\n",
    "    # Calculate the loss\n",
    "    loss = criterion(outputs, target_images)\n",
    "\n",
    "    # Backward pass: compute the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
